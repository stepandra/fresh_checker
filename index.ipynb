{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all unique swappers first tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from math import ceil\n",
    "\n",
    "# Load the swap.pkl dataset\n",
    "df = pd.read_pickle('df_total_cut_11Apr_15Apr.pkl', compression='gzip')\n",
    "\n",
    "# Specify the token address and pool address\n",
    "token_address = '0xbe0dbc7d9a93e7f2a98b3218ac82e2a7e7ccb3e5'\n",
    "# '0x0a13a5929e5f0ff0eaba4bd9e9512c91fce40280'\n",
    "pool_address = '0x116de4c81d2828c838ec14d5cd9663fa8711065a'\n",
    "# '0x01f4916850f37d262108a31aa7e1367441eba344'\n",
    "\n",
    "# Filter the dataframe for swaps involving the current token and pool\n",
    "filtered_swaps_xcorp = df[(df['buyCurrency.address'] == token_address) & (df['smartContract.address.address'] == pool_address)]\n",
    "\n",
    "# Get all unique swapper addresses\n",
    "unique_swappers_xorp = filtered_swaps_xcorp['transaction.txFrom.address'].unique()\n",
    "\n",
    "# Print the result\n",
    "url = 'https://graphql.bitquery.io/'\n",
    "\n",
    "# Split the unique swappers into batches of 200 addresses\n",
    "batches = [unique_swappers_xorp[i:i + 200] for i in range(0, len(unique_swappers_xorp), 200)]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over the batches\n",
    "for batch in batches:\n",
    "    # Define the query\n",
    "    batch_list = batch.tolist()\n",
    "    query = {\n",
    "        'query': '''\n",
    "        query {\n",
    "          ethereum {\n",
    "            transfers {\n",
    "              first_tx_time: minimum(of: time)\n",
    "              first_block: minimum(of: block)\n",
    "              first_tx_hash: minimum(of: time, get: tx_hash)\n",
    "              first_tx_sender: minimum(of: time, get: sender)\n",
    "              first_tx_currrency_address: minimum(of: time, get: currency_address)\n",
    "              first_tx_currrency_symbol: minimum(of: time, get: currency_symbol)\n",
    "              count\n",
    "              receiver(\n",
    "                receiver: {in: BATCH}\n",
    "              ) {\n",
    "                address\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        '''.replace('BATCH', json.dumps(batch_list))\n",
    "    }\n",
    "    headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'X-API-KEY': 'BQYvbQFK4xjlGgzv8IwQahp71H7Z4dDT'\n",
    "    }\n",
    "    \n",
    "    # Send the request\n",
    "    response = requests.post(url,headers=headers, json=query)\n",
    "\n",
    "    # Parse the response\n",
    "    data = json.loads(response.text)        \n",
    "\n",
    "    # Extract the transfers and add them to the results\n",
    "    results.extend(data['data']['ethereum']['transfers'])\n",
    "\n",
    "# Write the results to a JSON file\n",
    "with open('bq_xcorp_check_first_tx_data.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match unique with CEX addresses and get fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of fresh addresses that were fullfilled from CEX within the last 24 hours is: 57\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import json\n",
    "# from datetime import datetime, timedelta\n",
    "# import pytz\n",
    "\n",
    "# Load the Dune dataset\n",
    "dune_df = pd.read_csv('dune_default_cex.csv')\n",
    "\n",
    "# Load the Bitquery results\n",
    "with open('bitquery_check_first_tx_data.json', 'r') as f:\n",
    "    bitquery_data = json.load(f)\n",
    "\n",
    "bitquery_df_xorp = pd.DataFrame(bitquery_data)\n",
    "\n",
    "# Extract the receiver.address from the nested JSON objects in the 'receiver' column\n",
    "bitquery_df_xorp['receiver'] = bitquery_df_xorp['receiver'].apply(lambda x: x['address'])\n",
    "\n",
    "# Filter the unique swappers that match with the first_tx_sender from Bitquery results\n",
    "matched_swappers = bitquery_df_xorp[bitquery_df_xorp['first_tx_sender'].isin(dune_df['address'])]\n",
    "\n",
    "# merge two datasets\n",
    "merged_df_xai = pd.merge(matched_swappers, dune_df, left_on='first_tx_sender', right_on='address')\n",
    "\n",
    "# Add a new column 'CEX' and fill it with 'name' from dune_df\n",
    "merged_df_xai['CEX'] = merged_df_xai['name']\n",
    "\n",
    "\n",
    "first_swaps = filtered_swaps_xcorp.groupby('transaction.txFrom.address').first().reset_index()\n",
    "\n",
    "# Convert the 'receiver' column to just the address string. Run it only once\n",
    "# bitquery_df_xorp['receiver'] = bitquery_df_xorp['receiver'].apply(lambda x: x['address'])\n",
    "\n",
    "# Convert time columns to datetime and calculate the time difference\n",
    "bitquery_df_xorp['first_tx_time'] = pd.to_datetime(bitquery_df_xorp['first_tx_time'])\n",
    "first_swaps['block.timestamp.time'] = pd.to_datetime(first_swaps['block.timestamp.time'], utc=True)\n",
    "\n",
    "# Merge 'bitquery_df_xorp' with 'merged_df_xai' to add 'CEX' column\n",
    "bitquery_df_xorp = pd.merge(bitquery_df_xorp, merged_df_xai[['receiver', 'CEX']], on='receiver', how='left')\n",
    "\n",
    "# Convert the 'first_tx_time' column to datetime and remove the timezone\n",
    "bitquery_df_xorp['first_tx_time'] = bitquery_df_xorp['first_tx_time'].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "bitquery_df_xorp['first_swap_time'] = pd.to_datetime(first_swaps['block.timestamp.time']).dt.tz_localize(None)\n",
    "\n",
    "# Calculate the time difference in hourss\n",
    "bitquery_df_xorp['time_difference'] = (bitquery_df_xorp['first_swap_time'] - bitquery_df_xorp['first_tx_time']).dt.total_seconds() / 3600\n",
    "\n",
    "# Filter addresses where the time difference is less than 24 hours\n",
    "recent_addresses = bitquery_df_xorp[bitquery_df_xorp['time_difference'] < 24]\n",
    "\n",
    "# Count the number of such addresses\n",
    "address_count = len(recent_addresses)\n",
    "\n",
    "print(f'The number of fresh addresses that were fullfilled from CEX within the last 24 hours is: {address_count}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP 10 tokens from txt with the highest count of swaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of token addresses from the tokens06_15.txt file\n",
    "with open('tokens06_15.txt', 'r') as f:\n",
    "    token_addresses = [line.strip() for line in f]\n",
    "\n",
    "# Filter the dataframe to only include swaps involving the tokens from the list\n",
    "df = df[df['buyCurrency.address'].isin(token_addresses)]\n",
    "\n",
    "# Count the number of swaps associated with each token\n",
    "token_swap_counts = df['buyCurrency.address'].value_counts()\n",
    "\n",
    "# Get the top 10 tokens with the highest count of swaps\n",
    "top_10_tokens = token_swap_counts.head(10)\n",
    "\n",
    "print('The top 10 tokens with the highest count of swaps are:')\n",
    "print(top_10_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_addresses.to_excel('recent_addresses.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the token addresses\n",
    "with open('tokens06_15.txt', 'r') as f:\n",
    "    token_addresses = f.read().splitlines()\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "first_swappers = {}\n",
    "\n",
    "df = pd.read_pickle('df_total_cut_11Apr_15Apr.pkl', compression='gzip')\n",
    "\n",
    "# Iterate over each token address\n",
    "for token in token_addresses:\n",
    "    # Filter the dataframe for swaps involving the current token\n",
    "    token_swaps = df[df['buyCurrency.address'] == token]\n",
    "    # Sort by block height\n",
    "    token_swaps = token_swaps.sort_values('block.height', ascending=True)\n",
    "    # Check if there are any swaps\n",
    "    if not token_swaps.empty:\n",
    "        # The address of the first swapper is the 'txFrom.address' of the first row\n",
    "        first_swapper = token_swaps.iloc[0]['transaction.txFrom.address']\n",
    "        # Store the result\n",
    "        first_swappers[token] = first_swapper\n",
    "\n",
    "# Print the result\n",
    "for token, swapper in first_swappers.items():\n",
    "    print(f'The first address to swap with token {token} was {swapper}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "unpickled_df = pd.read_pickle('trades_with_freshcoin_uni2_06Apr_15Apr.pkl', compression='gzip')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
